/**
 * AI ìë§‰ ìƒì„± í†µí•© ëª¨ë“ˆ
 *
 * ì´ë¯¸ì§€ ë¶„ì„ â†’ ìë§‰ ìƒì„± â†’ ì¬ìƒ ì‹œê°„ ê³„ì‚°ì„ í†µí•©í•©ë‹ˆë‹¤.
 *
 * v2.0: Few-Shot Examples Library ì§€ì›
 * - ì™¸ë¶€ JSON ì˜ˆì‹œ íŒŒì¼ ì‚¬ìš© ê°€ëŠ¥
 * - ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì ìš©
 *
 * v3.0: 2ë‹¨ê³„ ë¶„ì„ ì‹œìŠ¤í…œ
 * - ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ â†’ ë§ì¶¤ ìë§‰ ìƒì„±
 * - ìë™ ë¶„ë¥˜ (ë©”íƒ€ë°ì´í„° â†’ ìºì‹œ â†’ AI)
 */

import { analyzeImageBatch, analyzeImageBatchTwoStep, isApiKeySet } from './vision.js';
import { calculateDuration, parseReadingSpeed } from '../video/duration-calculator.js';
import { PROMPT_TYPES, QUALITY_LEVELS, getAvailableExamples } from './prompt-templates.js';
import {
  classifyImages,
  groupByCategory,
  getClassificationStats,
  CATEGORIES
} from './classifier.js';

/**
 * ì‚¬ì§„ ë°°ì—´ì— AI ìë§‰ê³¼ ë™ì  ì¬ìƒ ì‹œê°„ì„ ì¶”ê°€
 * @param {Array} photos - ì‚¬ì§„ ë°°ì—´ (localPath í•„ìˆ˜)
 * @param {Object} options - ì˜µì…˜
 * @param {string} options.promptTemplate - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
 * @param {string} options.quality - í’ˆì§ˆ ë ˆë²¨ (creative|balanced|conservative)
 * @param {string} options.customExamplesPath - ì»¤ìŠ¤í…€ ì˜ˆì‹œ íŒŒì¼ ê²½ë¡œ (v2.0)
 * @param {string|number} options.readingSpeed - ì½ê¸° ì†ë„
 * @param {number} options.minDuration - ìµœì†Œ ì¬ìƒ ì‹œê°„
 * @param {number} options.maxDuration - ìµœëŒ€ ì¬ìƒ ì‹œê°„
 * @param {boolean} options.autoClassify - ìë™ ë¶„ë¥˜ í™œì„±í™” (v3.0)
 * @param {boolean} options.twoStepAnalysis - 2ë‹¨ê³„ ë¶„ì„ í™œì„±í™” (v3.0)
 * @param {boolean} options.showClassification - ë¶„ë¥˜ ê²°ê³¼ í‘œì‹œ (v3.0)
 * @param {Function} options.onProgress - ì§„í–‰ ìƒí™© ì½œë°±
 * @returns {Promise<Array>} AI ìë§‰ì´ ì¶”ê°€ëœ ì‚¬ì§„ ë°°ì—´
 */
export async function generateSubtitles(photos, options = {}) {
  const {
    promptTemplate = 'default',
    quality = 'balanced',
    customExamplesPath = null,
    readingSpeed = 250,
    minDuration = 2.0,
    maxDuration = 6.0,
    autoClassify = false,
    twoStepAnalysis = false,
    showClassification = false,
    onProgress
  } = options;

  // API í‚¤ í™•ì¸
  if (!isApiKeySet()) {
    throw new Error(
      'AI ìë§‰ ìƒì„±ì„ ìœ„í•´ GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\n' +
      'API í‚¤ ë°œê¸‰: https://aistudio.google.com/apikey'
    );
  }

  // ì½ê¸° ì†ë„ íŒŒì‹±
  const cpm = parseReadingSpeed(readingSpeed);

  // v3.0: ìë™ ë¶„ë¥˜ ë˜ëŠ” 2ë‹¨ê³„ ë¶„ì„ ëª¨ë“œ
  if (autoClassify || twoStepAnalysis) {
    return await generateSubtitlesTwoStep(photos, {
      quality,
      readingSpeed: cpm,
      minDuration,
      maxDuration,
      showClassification,
      onProgress
    });
  }

  // ê¸°ì¡´ ë°©ì‹ (v2.0): ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ë¶„ì„
  const progressWrapper = onProgress
    ? (info) => {
        const { current, total, photoId, status, subtitle } = info;
        if (status === 'analyzing') {
          onProgress(`  [${current}/${total}] ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...`);
        } else if (status === 'done') {
          onProgress(`  [${current}/${total}] "${subtitle}" ìƒì„±ë¨`);
        } else if (status === 'error') {
          onProgress(`  [${current}/${total}] ë¶„ì„ ì‹¤íŒ¨ (${photoId})`);
        }
      }
    : undefined;

  // AI ë¶„ì„ ì‹¤í–‰
  const subtitleMap = await analyzeImageBatch(photos, {
    promptTemplate,
    quality,
    customExamplesPath,
    onProgress: progressWrapper
  });

  // ê²°ê³¼ ì ìš©
  const enrichedPhotos = photos.map(photo => {
    const aiSubtitle = subtitleMap.get(photo.id);

    // ìë§‰ ìš°ì„ ìˆœìœ„: AI ìƒì„± > ì›ë³¸ title > ê·¸ë£¹ëª…
    const finalSubtitle = aiSubtitle || photo.title || photo.groupTitle || '';

    // ë™ì  ì¬ìƒ ì‹œê°„ ê³„ì‚°
    const dynamicDuration = calculateDuration(finalSubtitle, {
      readingSpeed: cpm,
      minDuration,
      maxDuration
    });

    return {
      ...photo,
      aiSubtitle,
      finalSubtitle,
      dynamicDuration
    };
  });

  return enrichedPhotos;
}

/**
 * v3.0: 2ë‹¨ê³„ ë¶„ì„ìœ¼ë¡œ ìë§‰ ìƒì„±
 * 1ë‹¨ê³„: ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ + ë¶„ë¥˜
 * 2ë‹¨ê³„: íŠ¹ì§• ê¸°ë°˜ ë§ì¶¤ ìë§‰ ìƒì„±
 *
 * @param {Array} photos - ì‚¬ì§„ ë°°ì—´
 * @param {Object} options - ì˜µì…˜
 * @returns {Promise<Array>} AI ìë§‰ì´ ì¶”ê°€ëœ ì‚¬ì§„ ë°°ì—´
 */
async function generateSubtitlesTwoStep(photos, options = {}) {
  const {
    quality = 'balanced',
    readingSpeed = 250,
    minDuration = 2.0,
    maxDuration = 6.0,
    showClassification = false,
    onProgress
  } = options;

  if (onProgress) {
    onProgress('ğŸ” 2ë‹¨ê³„ AI ë¶„ì„ ì‹œì‘...');
  }

  // 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ë¥˜ ë° íŠ¹ì§• ì¶”ì¶œ
  if (onProgress) {
    onProgress('  [1/2] ì´ë¯¸ì§€ ë¶„ë¥˜ ë° íŠ¹ì§• ì¶”ì¶œ ì¤‘...');
  }

  const classificationMap = await classifyImages(photos, {
    onProgress: showClassification ? (msg) => onProgress(`    ${msg}`) : undefined
  });

  // ë¶„ë¥˜ í†µê³„ ì¶œë ¥
  if (showClassification && onProgress) {
    const stats = getClassificationStats(classificationMap);
    onProgress(`  ğŸ“Š ë¶„ë¥˜ ê²°ê³¼: ${stats.total}ì¥`);
    for (const [category, count] of Object.entries(stats.byCategory)) {
      const percent = ((count / stats.total) * 100).toFixed(0);
      onProgress(`     â€¢ ${category}: ${count}ì¥ (${percent}%)`);
    }
    onProgress(`     í‰ê·  ì‹ ë¢°ë„: ${stats.avgConfidence}`);
  }

  // 2ë‹¨ê³„: íŠ¹ì§• ê¸°ë°˜ ë§ì¶¤ ìë§‰ ìƒì„±
  if (onProgress) {
    onProgress('  [2/2] íŠ¹ì§• ê¸°ë°˜ ë§ì¶¤ ìë§‰ ìƒì„± ì¤‘...');
  }

  // ë¶„ë¥˜ ê²°ê³¼ë¥¼ preExtractedFeaturesë¡œ ë³€í™˜
  const preExtractedFeatures = new Map();
  for (const [photoId, result] of classificationMap) {
    preExtractedFeatures.set(photoId, {
      category: result.category,
      mainSubject: result.mainSubject,
      features: result.features,
      confidence: result.confidence
    });
  }

  // 2ë‹¨ê³„ ë¶„ì„ ì‹¤í–‰
  const progressWrapper = onProgress
    ? (info) => {
        const { current, total, status, subtitle, category } = info;
        if (status === 'analyzing') {
          onProgress(`    [${current}/${total}] ìë§‰ ìƒì„± ì¤‘...`);
        } else if (status === 'done') {
          const categoryLabel = category || 'default';
          onProgress(`    [${current}/${total}] [${categoryLabel}] "${subtitle}"`);
        } else if (status === 'error') {
          onProgress(`    [${current}/${total}] ìƒì„± ì‹¤íŒ¨`);
        }
      }
    : undefined;

  const resultsMap = await analyzeImageBatchTwoStep(photos, {
    preExtractedFeatures,
    onProgress: progressWrapper
  });

  // ê²°ê³¼ ì ìš©
  const enrichedPhotos = photos.map(photo => {
    const result = resultsMap.get(photo.id);
    const classification = classificationMap.get(photo.id);

    const aiSubtitle = result?.subtitle || null;
    const finalSubtitle = aiSubtitle || photo.title || photo.groupTitle || '';

    // ë™ì  ì¬ìƒ ì‹œê°„ ê³„ì‚°
    const dynamicDuration = calculateDuration(finalSubtitle, {
      readingSpeed,
      minDuration,
      maxDuration
    });

    return {
      ...photo,
      aiSubtitle,
      finalSubtitle,
      dynamicDuration,
      // v3.0 ì¶”ê°€ ì •ë³´
      classification: classification ? {
        category: classification.category,
        features: classification.features,
        mainSubject: classification.mainSubject,
        confidence: classification.confidence,
        source: classification.source
      } : null
    };
  });

  if (onProgress) {
    onProgress('âœ… 2ë‹¨ê³„ AI ë¶„ì„ ì™„ë£Œ');
  }

  return enrichedPhotos;
}

/**
 * AI ìë§‰ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
 * @returns {{available: boolean, reason?: string}}
 */
export function checkAvailability() {
  if (!isApiKeySet()) {
    return {
      available: false,
      reason: 'GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ'
    };
  }

  return { available: true };
}

/**
 * ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ëª©ë¡
 */
export { PROMPT_TYPES };

/**
 * ì‚¬ìš© ê°€ëŠ¥í•œ í’ˆì§ˆ ë ˆë²¨ ëª©ë¡
 */
export { QUALITY_LEVELS };

/**
 * ì˜ˆì‹œ í…œí”Œë¦¿ ì •ë³´ ì¡°íšŒ
 */
export { getAvailableExamples };
